\documentclass[11pt,letterpaper,twoside,openany]{book}
%\usepackage{lineno}
%\usepackage{afterpage}
\usepackage[pdftex]{graphicx}
\usepackage[pdftex, pdfborder={0 0 0}]{hyperref}
\usepackage[pdftex]{lscape}
\usepackage{listings}
%\usepackage{longtable}
%\usepackage{fancyvrb}
\usepackage{zed-csp}
\usepackage{tikz-uml}
\usepackage{float}

%\lstset{basicstyle=\tiny}
\lstset{basicstyle=\small}

\addtolength{\textheight}{0.6in}
%\addtolength{\textheight}{1.25in}

\addtolength{\textwidth}{0.6in}
%\addtolength{\textwidth}{0.5in}

%\setlength{\parskip}{5pt plus1pt minus1pt}
%\addtocounter{secnumdepth}{1}

\pagestyle{plain}
%\linenumbers

\begin{document}
\title{Design of the \emph{HiRTOS} Multi-core \\
       Real-Time Operating System}
\author{Germ\'an Rivera \\
        \texttt jgrivera67@gmail.com}
\date{\today}
\maketitle

\frontmatter
\tableofcontents
%\listoffigures

\mainmatter
\raggedbottom
\pagestyle{myheadings}
\markboth{Design of the HiRTOS Multi-core Real-Time Operating System}{Design of the HiRTOS Real-Time Operating System}

\chapter{Introduction}

This document describes the design of \emph{HiRTOS} (\emph{``High Integrity''} RTOS),
a real-time operating system kernel (RTOS) written in SPARK Ada. HiRTOS targets
safety-critical and security-sensitive embedded software applications that run
in small multi-core microcontrollers. HiRTOS was designed using the Z notation,
as a methodical way to capture correctness properties that can be expressed
as programming contracts in SPARK Ada. Z is a software modeling notation based
on discrete mathematics structures (such as sets, relations and functions)
and predicate logic.

Although there are several popular RTOSes for embedded applications that run on small
multi-core microcontrollers, most of them are not designed with high-integrity applications
in mind, and are typically written in C, a notoriously unsafe language. So, it would be desirable
to have an RTOS specifically designed for high-integrity applications, and written in a safer
language, like Ada or its subset SPARK Ada, even if application code is written in C/C++.
Modern versions of the Ada and SPARK languages have programming-by-contract constructs built-in
in the language, which allows the programmer to express correctness properties, such as
preconditions, postconditions, object state invariants and loop invariants, as code.
However, one challenge when doing programming-by-contract is to be aware of all the correctness
conditions that can be asserted in programming contracts. Describing software design in a formal
notation, such as the \href{http://en.wikipedia.org/wiki/Z_notation}{Z notation} \cite{Zref, Zrm, WayofZ},
can help identify/elicit such correctness conditions in a more thorough and methodical way than just
writing code.

Z is a software modeling notation based on discrete mathematics structures (such as sets,
relations and functions) and predicate logic. With Z, data structures can be specified in
terms of mathematical structures and their state invariants can be specified using mathematical
predicates. The pre-conditions and post-conditions of the operations that manipulate
the data structures can also be specified using predicates. Using Z for this purpose encourages
a rigorous and methodical thought process to elicit correctness properties, in a systematic way.
The \emph{HiRTOS} Z model described here was checked with the \verb'fuzz' tool~\cite{Fuzz}, a
Z type-checker, that catches Z type mismatches in predicates.

The code of \emph{HiRTOS} is written in SPARK Ada \cite{SparkAda}, a high integrity
subset of the Ada programming language. The code of HiRTOS is available in GitHub at
\url{https://github.com/jgrivera67/HiRTOS}. HiRTOS data types were modeled in Z at a
level of abstraction that can be mapped directly to corresponding data types in SPARK Ada.
This guided design decisions at the code level, resulting in a completely pointer-less
implementation, that leverages the various Ada mechanisms to avoid having to use pointers.

Also, the HiRTOS thread scheduler was modeled in TLA+/PlusCal \cite{tla1, tla2} and the
hiRTOS TLA+ model was verified using the TLC model checker \cite{tlc}.

\chapter{HiRTOS Overview}

\section{RTOS Major Design Decisions}

\begin{itemize}
\item For API simplicity, mutexes and condition variables \cite{threads1, threads2} are the only
synchronization primitives in \emph{HiRTOS}, similar to the thread synchronization primitives of
the C11 standard library \cite{libcThreads}.
Other synchronization primitives such as semaphores, event flags and message queues can be
implemented on top of mutexes and condition variables.

\item Unlike C11 mutexes, \emph{HiRTOS} mutexes can change the priority of the thread owning the
mutex. \emph{HiRTOS} mutexes support both priority inheritance and priority ceiling \cite{prioCeiling}.

\item Unlike C11 condition variables, \emph{HiRTOS} condition variables
can also be waited on while having interrupts disabled, not just while holding a mutex.
This prevents missing "thread wakeups", when signaling condition variables from interrupt
service routines (ISRs), making it unnecessary to use semaphores for this purpose.

\item \emph{HiRTOS} atomic levels can be used to disable the thread scheduler or to disable interrupts
at and below a given priority or to disable all interrupts.

\item In a multi-core platform, there is one \emph{HiRTOS} instance per CPU Core. Each \emph{HiRTOS}
instance is independent of each other. No resources are shared between \emph{HiRTOS} instances. No
communication/synchronization between CPU cores is supported by the current version of \emph{HiRTOS}.
If an application needs inter-core communication, that would need to be provided outside of
\emph{HiRTOS}, using doorbell interrupts and mailboxes or shared memory, for example.

\item
Threads are bound to the CPU core in which they were created, for the lifetime of the thread. That is,
no thread migration between CPU cores is supported.

\item
All RTOS objects such as threads, mutexes and condition variables are allocated internally
by \emph{HiRTOS} from statically allocated internal object pools.
These object pools are just RTOS-private global arrays of the corresponding RTOS object types,
sized at compile time via configuration parameters, whose values are application-specific.
RTOS object handles provided to application code are just indices into these internal object arrays.
No actual RTOS object pointers exposed to application code. No dynamic allocation/deallocation of
RTOS objects is supported and no static allocation of RTOS objects in memory owned by application
code is supported either. All this prevents HiRTOS internal state from being accidentally or
intentionally corrupted from application code. RTOS objects can only be manipulated through the
HiRTOS APIs.

\item
All application threads run in unprivileged mode by default. In unprivileged mode, a thread can only
access its own stack. To access global variables or MMIO space, application threads must explicitly
request either read-only or read-write permission to \emph{HiRTOS} via a system call.

\item ISRs are seen as hardware-scheduled threads that have higher priority than all software-scheduled
threads. They can only be preempted by higher-priority ISRs. They cannot block waiting on mutexes or
condition variables.

\end{itemize}

\section{Separation Kernel Major Design Decisions}

Besides being a fully functional RTOS, HiRTOS can be used as a separation kernel \cite{SepK1, SepK2}.
A separation kernel can be seen as an RTOS that schedules partitions instead of threads. A partition
is a spatial and temporal separation/isolation unit on which a bare-metal or RTOS-based firmware
binary runs. A separation kernel requires that the target CPU supports hypervisor privilege mode
and two-stage memory protection.

\begin{itemize}

\item In a multi-core platform, there is one separation kernel instance per CPU Core. Each instance is
independent of each other. No resources are shared between separation kernel instances. No communication
between CPU cores is supported yet. If needed by the application, inter-core communication would need to
be provided outside of the HiRTOS separation kernel, using doorbell interrupts and mailboxes or shared
memory, for example.

\item Each separation-kernel instance consists of one or more partitions. A partition is a spatial and
temporal separation/isolation unit on which a bare-metal or RTOS-based firmware binary runs. Each partition
consists of one or more disjoint address ranges covering portions of RAM and MMIO space that only that
partition can access. Isolation is enforced by a hypervisor-level memory protection unit (MPU). Also,
each partition has its own interrupt vector table and its own set of physical interrupts. So, physical
peripherals can be assigned to individual partitions (discrete device assignment). However,
no device or memory virtualisation is supported, as the target machine for the HiRTOS separation kernel
is not required to have neither an MMU nor an IOMMU.
The CPU core is time-sliced among the partitions running on the same separation kernel instance.

\item
Partitions are bound to the CPU core in which they were created. That is, no partition migration between
CPU cores is supported.

\item
Partitions are created at boot time before starting the partition scheduler on the corresponding CPU core.
Partitions cannot be destroyed or terminated.

\item
The separation kernel code itself runs in hypervisor privilege mode. All partitions run at a privilege lower
than hypervisor mode. Partitions can communicate with the separation kernel via hypervisor calls and via
traps to hypervisor mode triggered from special machine instructions such as $WFI$. The separation kernel
can communicate with partitions, by forwarding interrupts targeted to the corresponding partition.

\end{itemize}

\section{HiRTOS Code Architecture}

To have wider adoption of an RTOS written in bare-metal Ada, providing a C/C++ programming interface
is a must. Indeed, multiple interfaces or ``skins'' can be provided to mimic widely popular
RTOSes such as FreeRTOS \cite{freeRTOS} and RTOS interfaces such as the CMSIS RTOS2 API \cite{cmsisRTOS}.
As shown on figure \ref{HiRTOSAchitecture1}, HiRTOS has a C/C++ interface layer that provides
a FreeRTOS skin and and a CMSIS RTOS2 skin. Both skins are implemented on top of a native C skin.
The native C skin is just a thin C wrapper that consists of a C header file containing the C
functions prototypes of the corresponding Ada subprograms of the SPARK Ada native interface of HiRTOS.

In addition to the Ada native and C/C++ interfaces, HiRTOS could also provide an Ada runtime library (RTS) skin,
as shown on figure \ref{HiRTOSAchitecture2}, so that baremetal Ada applications that use Ada tasking
features can run on top of HiRTOS. This can be especially useful, given the limited number of
microcontroller platforms for which an available bare-metal Ada runtime library is provided with the
GNAT Ada compiler.

HiRTOS has been architected to be easily portable to any single-core or multi-core microcontroller or
bare metal platform for which a GNAT Ada cross compiler is available. All platform-dependent code is
isolated in the HiRTOS porting layer, which provides platform-independent interfaces to the rest of
the HiRTOS code.
To avoid any dependency on a platform-specific bare-metal Ada runtime library, provided by the
compiler, HiRTOS sits on top of a platform-independent portable minimal Ada runtime library.
Currently, two porting layers have been implemented: one for the ARM Cortex-R52 multi-core processor,
and the other for the RISCV-based ESP32-C3 microcontroller. To port HiRTOS to a new target platform,
the platform-specific components of the porting layer would need to be implemented for the new platform.

\begin{figure}
   \begin{center}
      \scalebox{0.45}{
         \begin{tikzpicture}
            \umlemptypackage[x=0, y=0]{Bare Metal C/C++ Applications}

            \begin{umlpackage}[x=0, y=-4]{C Interface Skins Library}
               \umlemptypackage[x=-3]{CMSIS RTOS2 Skin}
               \umlemptypackage[x=3]{FreeRTOS Skin}
               \umlemptypackage[x=6, y=-3]{C Interface Skin}
            \end{umlpackage}

            \begin{umlpackage}[x=0, y=-2]{HiRTOS Library Crate}
               \umlemptypackage[x=0, y=-10]{HiRTOS}
               \umlemptypackage[x=-4, y=-12]{HiRTOS Porting Layer}
            \end{umlpackage}

            \umlemptypackage[x=2, y=-18]{Portable Minimal Ada RTS Library Crate}

            \umlimport[geometry=|-]{CMSIS RTOS2 Skin}{C Interface Skin}
            \umlimport[geometry=|-]{FreeRTOS Skin}{C Interface Skin}
            \umlimport[geometry=|-]{C Interface Skin}{HiRTOS}
            \umlimport[geometry=|-]{HiRTOS}{HiRTOS Porting Layer}
            \umlimport[]{HiRTOS}{Portable Minimal Ada RTS Library Crate}
            \umlimport[geometry=|-]{HiRTOS Porting Layer}{Portable Minimal Ada RTS Library Crate}
            \umlimport[]{Bare Metal C/C++ Applications}{CMSIS RTOS2 Skin}
            \umlimport[]{Bare Metal C/C++ Applications}{FreeRTOS Skin}
            \umlimport[geometry=-|]{Bare Metal C/C++ Applications}{C Interface Skin}
         \end{tikzpicture}
      }
   \end{center}
   \caption{HiRTOS Code Architecture for C/C++ Applications}
   \label{HiRTOSAchitecture1}
\end{figure}

\begin{figure}
   \begin{center}
      \scalebox{0.45}{
         \begin{tikzpicture}
            \umlemptypackage[x=0, y=0]{Bare Metal Ada Applications}

            \umlemptypackage[x=-6, y=-4]{Ada RTS Tasking Skin Library Crate}

            \begin{umlpackage}[x=0, y=0]{HiRTOS Library Crate}
               \umlemptypackage[x=0, y=-10]{HiRTOS}
               \umlemptypackage[x=-4, y=-12]{HiRTOS Porting Layer}
            \end{umlpackage}

            \umlemptypackage[x=+4, y=-16]{Portable Minimal Ada RTS Library Crate}

            \umlimport[]{Ada RTS Tasking Skin Library Crate}{HiRTOS}
            \umlimport[geometry=|-]{HiRTOS}{HiRTOS Porting Layer}
            \umlimport[]{HiRTOS}{Portable Minimal Ada RTS Library Crate}
            \umlimport[geometry=|-]{HiRTOS Porting Layer}{Portable Minimal Ada RTS Library Crate}
            \umlimport[]{Bare Metal Ada Applications}{Ada RTS Tasking Skin Library Crate}
            \umlimport[]{Bare Metal Ada Applications}{HiRTOS}
            \umlimport[geometry=-|]{Bare Metal Ada Applications}{Portable Minimal Ada RTS Library Crate}
         \end{tikzpicture}
      }
   \end{center}
   \caption{HiRTOS Code Architecture for Ada Applications}
   \label{HiRTOSAchitecture2}
\end{figure}

Figure \ref{HiRTOSAchitecture3} shows the major code components of HiRTOS. The HiRTOS code base is
structured in three conceptual layers. The \emph{HiRTOS API} layer, the \emph{HiRTOS internals layer}
and the \emph{HiRTOS porting layer}.

The \emph{HiRTOS API} layer contains the HiRTOS public interface components.
The \verb'HiRTOS_Interrupt_Handling' Ada package contains the services to be invoked from top-level
interrupt handlers to notify HiRTOS of entering an exiting interrupt context.
\verb'HiRTOS_Memory_Protection' contains the services to protect ranges of memory and MMIO space.
\verb'HiRTOS_Thread' contains the services to create and manage threads.

The \emph{HiRTOS internals layer} contains HiRTOS-private components that are
hardware-independent.

The \emph{HiRTOS porting layer} contains hardware-dependent components that
provide hardware-independent interfaces to upper HiRTOS layers.

\begin{figure}
   \begin{center}
      \scalebox{0.50}{
         \begin{tikzpicture}
            \begin{umlpackage}{HiRTOS}
               \begin{umlpackage}{HiRTOS API}
                  \umlbasiccomponent{HiRTOS}
                  \umlbasiccomponent[name=HiRTOSinterruptHandling, x=-4, y=-2.5]{HiRTOS.Interrupt\_Handling}
                  \umlbasiccomponent[name=HiRTOSmemoryProtection, x=2, y=-2.5]{HiRTOS.Memory\_Protection}
                  \umlbasiccomponent[name=HiRTOSthread, x=-4, y=-5]{HiRTOS.Thread}
                  \umlbasiccomponent[name=HiRTOStimer, x=2, y=-5]{HiRTOS.Timer}
                  \umlbasiccomponent[name=HiRTOScondvar, x=-4, y=-7.5]{HiRTOS.Condvar}
                  \umlbasiccomponent[name=HiRTOSmutex, x=2, y=-7.5]{HiRTOS.Mutex}
               \end{umlpackage}
               \begin{umlpackage}{HiRTOS internals}
                  \umlbasiccomponent[name=RTOSprivate, x=0, y=-11]{RTOS\_Private}
                  \umlbasiccomponent[name=HiRTOSinterruptHandlingPrivate, x=-4, y=-13.5]{HiRTOS.Interrupt\_Handling\_Private}
                  \umlbasiccomponent[name=HiRTOSmemoryProtectionPrivate, x=3, y=-13.5]{HiRTOS.Memory\_Protection\_Private}
                  \umlbasiccomponent[name=HiRTOSthreadPrivate, x=-4, y=-16]{HiRTOS.Thread\_Private}
                  \umlbasiccomponent[name=HiRTOStimerPrivate, x=2, y=-16]{HiRTOS.TimerPrivate}
                  \umlbasiccomponent[name=HiRTOScondvarPrivate, x=-4, y=-18.5]{HiRTOS.CondvarPrivate}
                  \umlbasiccomponent[name=HiRTOSmutexPrivate, x=2, y=-18.5]{HiRTOS.MutexPrivate}
               \end{umlpackage}
               \umlbasiccomponent[name=GenericLinkedList, x=2, y=-21.5]{Generic\_Linked\_List}
               \umlbasiccomponent[name=GenericExecutionStack, x=-3, y=-21.5]{Generic\_Execution\_Stack}
            \end{umlpackage}

            \begin{umlpackage}{HiRTOS Porting Layer}
               \begin{umlpackage}{Cpu Architecture Specific}
                  \umlbasiccomponent[name=HiRTOScpuArchParameters, x=-4, y=-26]{HiRTOS\_Cpu\_Arch\_Parameters}
                  \umlbasiccomponent[name=HiRTOScpuArchInterface, x=-4, y=-28.5]{HiRTOS\_Cpu\_Interface}
                  \umlbasiccomponent[name=HiRTOScpuStartupInterface, x=-4, y=-31]{HiRTOS\_Cpu\_Startup\_Interface}
                  \umlbasiccomponent[name=HiRTOScpuMultiCoreInterface, x=-4, y=-33.5]{HiRTOS\_Cpu\_Multi\_Core\_Interface}
               \end{umlpackage}
               \begin{umlpackage}{Platform Specific}
                  \umlbasiccomponent[name=HiRTOSPlatformParameters, x=4, y=-26]{HiRTOS\_Platform\_Parameters}
                  \umlbasiccomponent[name=HiRTOScpuArchInterfaceInterrupts, x=4, y=-28.5]{HiRTOS\_Cpu\_Interface.Interrupts}
                  \umlbasiccomponent[name=HiRTOSlowLevelDebugInterface, x=4, y=-31]{HiRTOS\_Low\_Level\_Debug\_Interface}
               \end{umlpackage}
            \end{umlpackage}

            \umlimport[]{HiRTOS API}{HiRTOS internals}
            \umlimport[]{HiRTOS internals}{GenericLinkedList}
            \umlimport[]{HiRTOS internals}{GenericExecutionStack}
            \umlimport[]{HiRTOS}{HiRTOS Porting Layer}
         \end{tikzpicture}
      }
   \end{center}
   \caption{HiRTOS Code Components}
   \label{HiRTOSAchitecture3}
\end{figure}

\clearpage
\chapter{HiRTOS Z Specification}

\section{HiRTOS Data Structures}

\subsection{Z Naming Conventions}

The following naming conventions are used in the Z model of \emph{HiRTOS}:
\begin{itemize}
\item Z Primitive types are in uppercase.
\item Z Composite types (schema types) start with uppercase.
\item Z constants and variables start with lower case.
\item Identifiers that start with the $z$ prefix are meant to be modeling-only
      entities that do not physically correspond to code-level entities.
\end{itemize}

\subsection{\emph{HiRTOS} Configuration Parameters}

Constants defined here represent compile-time configuration parameters for
\emph{HiRTOS}.

\begin{axdef}
    maxNumThreads: \nat_1 \\
    maxNumMutexes: \nat_1 \\
    maxNumCondvars: \nat_1 \\
    maxNumTimers: \nat_1 \\
    numThreadPriorities: \nat_1 \\
    numTimerWheelSpokes: \nat_1 \\
\where
    maxNumThreads > 2
\also
    maxNumCondvars \geq maxNumThreads
\also
    maxNumTimers \geq maxNumThreads
\end{axdef}

The minimum number of threads that can be configured per CPU core is 2, which corresponds to the \emph{HiRTOS}
pre-defined threads: the idle thread and the tick timer thread. Each thread has a builtin timer, so the minimum number of timers that can be configured is $maxNumThreads$. Also, each thread
has a builtin condition variable, so the minimum number of condition variables that can be configured is $maxNumThreads$ as well.

\subsection{\emph{HiRTOS} Target Platform Parameters}

Constants defined here represent compile-time target platform parameters for
\emph{HiRTOS}.

\begin{axdef}
    numCpus: \nat_1 \\
    minMemoryAddress: \nat \\
    maxMemoryAddress: \nat_1 \\
    numInterruptPriorities: \nat_1 \\
    maxNumInterrupts: \nat_1 \\
\where
    minMemoryAddress < maxMemoryAddress
\end{axdef}

\subsection{\emph{HiRTOS} Primitive Types}

Below are the primitive types used in HiRTOS:

\begin{zed}
[CpuIdType] \\
\# CpuIdType = numCpus + 1 \\
[ThreadIdType] \\
\# ThreadIdType = maxNumThreads + 1 \\
[MutexIdType] \\
\# MutexIdType = maxNumMutexes + 1 \\
[CondvarIdType] \\
\# CondvarIdType = maxNumCondvars + 1 \\
[TimerIdType] \\
\# TimerIdType = maxNumTimers + 1 \\
[InterruptIdType] \\
\# InterruptIdType = maxNumInterrupts + 1 \\
\end{zed}

\begin{axdef}
   invalidCpuId : CpuIdType \\
   invalidThreadId : ThreadIdType \\
   invalidMutexId : MutexIdType \\
   invalidCondvarId : CondvarIdType \\
   invalidTimerId : TimerIdType \\
   invalidInterruptId : InterruptIdType \\
\end{axdef}

\begin{zed}
    [CpuRegistersType] \\
    ValidCpuIdType == CpuIdType \setminus \{ invalidCpuId \} \\
    MemoryAddressType == \\
    \t1 minMemoryAddress \upto maxMemoryAddress \\
    nullAddress == 0 \\
    ValidThreadIdType == \\
    \t1 ThreadIdType \setminus \{ invalidThreadId \} \\
    ValidMutexIdType == MutexIdType \setminus \{ invalidMutexId \} \\
    ValidCondvarIdType == \\
    \t1 CondvarIdType \setminus \{ invalidCondvarId \} \\
    ValidTimerIdType == TimerIdType \setminus \{ invalidTimerId \} \\
    ValidInterruptIdType == \\
    \t1 InterruptIdType \setminus \{ invalidInterruptId \} \\
    ThreadPriorityType == 0 \upto numThreadPriorities \\
    invalidThreadPriority == numThreadPriorities \\
    ValidThreadPriorityType == \\
    \t1 ThreadPriorityType \setminus \{ invalidThreadPriority \} \\
    InterruptPriorityType == 0 \upto numInterruptPriorities \\
    invalidInterruptPriority == numInterruptPriorities \\
    ValidInterruptPriorityType == \\
    \t1 InterruptPriorityType \setminus \{ invalidInterruptPriority \} \\
    AtomicLevelType == 0 \upto numInterruptPriorities + 1 \\
    atomicLevelNoInterrupts == min~AtomicLevelType \\
    atomicLevelSingleThread == max~AtomicLevelType - 1 \\
    atomicLevelNone == max~AtomicLevelType \\
    InterruptNestingCounterType == \\
    \t1 0 \upto numInterruptPriorities \\
    ActiveInterruptNestingCounterType == \\
    \t1 InterruptNestingCounterType \setminus \{~ 0 ~\} \\
    CpuInterruptMaskingStateType ::= \\
    \t1 cpuInterruptsEnabled | \\
    \t1 cpuInterruptsDisabled \\
    CpuPrivilegeType ::= cpuPrivileged | cpuUnprivileged \\
    MemoryProtectionStateType ::= \\
    \t1 memoryProtectionOn | memoryProtectionOff \\
    CpuExecutionModeType ::= \\
    \t1 cpuExecutingResetHandler | \\
    \t1 cpuExecutingInterruptHandler | \\
    \t1 cpuExecutingThread \\
    ThreadStateType ::= threadNotCreated | threadSuspended | \\
    \t5 threadRunnable | threadRunning | \\
    \t5 threadBlockedOnCondvar | threadBlockedOnMutex \\
    ThreadSchedulerStateType ::= \\
    \t1 threadSchedulerStopped | threadSchedulerRunning \\
\end{zed}

\begin{zed}
    ThreadQueueType == \iseq ValidThreadIdType \\
    MutexListType == \iseq ValidMutexIdType \\
    TimerWheelSpokeIndexType == \\
    \t1 0 \upto numTimerWheelSpokes \\
    invalidTimerWheelSpokeIndex == \\
    \t1 max~TimerWheelSpokeIndexType \\
    ValidTimerWheelSpokeIndexType == \\
    \t1 TimerWheelSpokeIndexType ~\setminus \\
    \t1 \{~ invalidTimerWheelSpokeIndex ~\} \\
    TimerKindType ::= periodicTimer | oneShotTimer \\
    TimerStateType ::= timerStopped | timerRunning \\
\end{zed}

For interrupts, lower priority values represent higher priorities. For threads, lower priority
values represent lower priorities.

\subsection{\emph{HiRTOS} Axiomatic Definitions}

\begin{axdef}
    zAddressRange : \\
    \t1 (MemoryAddressType \cross MemoryAddressType) \inj \\
    \t1 \finset_1 MemoryAddressType
\where
    \forall x, y : MemoryAddressType | \\
   \t1  (x, y) \in \dom zAddressRange @ \\
   \t1 x < y \land zAddressRange(x, y) = x \upto y
\end{axdef}

\begin{axdef}
   zCpuToISRstackAddressRange: \\
   \t1 ValidCpuIdType \inj \\
   \t1 (MemoryAddressType \cross MemoryAddressType) \\
\where
   \bigcap~\{~ i: ValidCpuIdType @ \\
     zAddressRange(zCpuToISRstackAddressRange(i)) ~\} = \emptyset
\also
   \forall i : \dom zCpuToISRstackAddressRange @ \\
      \# (zAddressRange(zCpuToISRstackAddressRange(i))) \geq 2
\end{axdef}

\begin{axdef}
   interruptPriorities: \\
   \t1 InterruptIdType \fun InterruptPriorityType
\end{axdef}
%\clearpage

\subsection{\emph{HiRTOS} State Variables}

The $HiRtos$ schema represents the multi-core RTOS state variables (internal data
structures). All HiRTOS objects such as threads, mutexes,
condition variables and software timers are statically allocated
internally by HiRTOS.

\begin{schema}{HiRtos}
    rtosCpuInstances: \\
    \t1 ValidCpuIdType \inj HiRtosCpuInstanceType \\
    zAllCreatedThreadInstances: \finset ThreadType \\
\where
    \# rtosCpuInstances \geq 1
\also
    \forall i : \dom rtosCpuInstances @ \\
\t1   (rtosCpuInstances(i)).cpuId = i
\also
    zAllCreatedThreadInstances = \\
\t1    \bigcup~\{~ i: ValidCpuIdType @ \\
\t2    \ran (rtosCpuInstances(i)).threads ~\}
\also
    \bigcap~\{~ i: ValidCpuIdType @ \\
\t1    \ran (rtosCpuInstances(i)).threads ~\} = \emptyset
\also
    \bigcap~\{~ thread: zAllCreatedThreadInstances @ \\
\t1    zAddressRange(thread.stack) ~\} = \emptyset
\also
    \bigcap~\{~ i: ValidCpuIdType @ \\
\t1    \ran (rtosCpuInstances(i)).mutexes ~\} = \emptyset
\also
    \bigcap~\{~ i: ValidCpuIdType @ \\
\t1    \ran (rtosCpuInstances(i)).condvars ~\} = \emptyset
\also
    \bigcap~\{~ i: ValidCpuIdType @ \\
\t1    \ran (rtosCpuInstances(i)).timers ~\} = \emptyset
\end{schema}

\subsubsection{Per-CPU HiRTOS Instance}

The state variables and internal data structures of each per-CPU \emph{HiRTOS} instance
are described below:

\begin{schema}{HiRtosCpuInstanceType}
    cpuId: CpuIdType \\
    currentCpuContext: CpuRegistersType \\
    threadSchedulerState: ThreadSchedulerStateType \\
    currentAtomicLevel: AtomicLevelType \\
    currentCpuExecutionMode: CpuExecutionModeType \\
    currentThreadId: ThreadIdType \\
    timerTicksSinceBoot: \nat \\
    idleThreadId: ValidThreadIdType \\
    tickTimerThreadId: ValidThreadIdType \\
    interruptNestingLevelStack: InterruptNestingLevelStackType \\
    threads: ValidThreadIdType \finj ThreadType \\
    mutexes: ValidMutexIdType \finj MutexType \\
    condvars: ValidCondvarIdType \finj CondvarType \\
    timers: ValidTimerIdType \finj TimerType \\
    runnableThreadsQueue : ThreadPriorityQueueType \\
    timerWheel: TimerWheelType \\
    zCpuInterruptMaskingState: CpuInterruptMaskingStateType \\
    zCpuPrivilege: CpuPrivilegeType \\
    zMemoryProtectionState: MemoryProtectionStateType \\
\where
    \{~ idleThreadId, tickTimerThreadId ~\} \subseteq \dom threads
\also
    tickTimerThreadId \neq idleThreadId
\also
    threadSchedulerState = threadSchedulerRunning \implies \\
    (\forall threadId: (\dom threads \setminus \{~ currentThreadId ~\}) @ \\
\t1    (threads(threadId)).currentPriority \leq (threads(currentThreadId)).currentPriority)
\also
    zCpuInterruptMaskingState = cpuInterruptsEnabled \iff \\
\t1 currentAtomicLevel > atomicLevelNoInterrupts
\also
    zCpuInterruptMaskingState = cpuInterruptsDisabled \implies zCpuPrivilege = cpuPrivileged
\also
    currentAtomicLevel < atomicLevelNone \implies zCpuPrivilege = cpuPrivileged
\also
    \bigcap~\{~ t: \ran threads @ \{~ t.builtinCondvarId ~\} ~\} = \emptyset
\also
    \bigcap~\{~ t: \ran threads @ \{~ t.builtinTimerId ~\} ~\} = \emptyset
\also
    \forall t: \ran threads @ (t.id = (threads \inv)(t) \land \\
    (t.ownedMutexes \neq \emptyset \implies \\
     t.currentPriority = max~ \{~ m : \ran t.ownedMutexes @ (mutexes(m)).ceilingPriority ~\}))
\also
    \forall m: \ran mutexes @ m.id = mutexes\inv(m)
\also
    \forall c: \ran condvars @  c.id = condvars\inv(c)
\also
    \forall ti: \ran timers @ ti.id = timers\inv(ti)
\also
    \forall p: ValidThreadPriorityType @ \\
\t1    \forall threadId: \ran (runnableThreadsQueue.threadQueues(p)) @ \\
\t2    (threads(threadId)).currentPriority = p
\end{schema}

\begin{schema}{ThreadPriorityQueueType}
    threadQueues: \\
    \t1 ValidThreadPriorityType \inj ThreadQueueType \\
    waitingThreadsCount: \nat
\where
   waitingThreadsCount = \\
   \# (\bigcup ~\{~ p: ValidThreadPriorityType @ threadQueues(p) ~\})
\end{schema}

\begin{schema}{InterruptNestingLevelStackType}
       interruptNestingLevels: \\
    \t1 ActiveInterruptNestingCounterType \inj \\
    \t1 InterruptNestingLevelType \\
    currentInterruptNestingCounter: \\
    \t1 InterruptNestingCounterType \\
    zCpuId: ValidCpuIdType
\where
   \forall x: \dom interruptNestingLevels @ \\
\t1   (interruptNestingLevels(x)).interruptNestingCounter = x \\
\t1   \land \\
\t1   (interruptNestingLevels(x)).savedStackPointer \in \\
\t1        zAddressRange(zCpuToISRstackAddressRange(zCpuId))
\also
   \dom interruptNestingLevels = \\
   1 \upto currentInterruptNestingCounter
\end{schema}

\begin{schema}{InterruptNestingLevelType}
   interruptId : InterruptIdType \\
   interruptNestingCounter: ActiveInterruptNestingCounterType \\
   savedStackPointer: MemoryAddressType \\
   atomicLevel: AtomicLevelType \\
\where
   atomicLevel \leq interruptPriorities (interruptId)
\also

\end{schema}

\begin{schema}{TimerWheelType}
   wheelSpokesHashTable: \\
   \t1 ValidTimerWheelSpokeIndexType \fun \finset ValidTimerIdType \\
   currentWheelSpokeIndex: ValidTimerWheelSpokeIndexType
\where
    \forall i, j: ValidTimerWheelSpokeIndexType | i \neq j @ \\
    \t1 wheelSpokesHashTable(i) \cap wheelSpokesHashTable(j) = \emptyset
\end{schema}

\begin{schema}{TimerType}
   id : TimerIdType \\
   timerKind : TimerKindType \\
   timerState : TimerStateType \\
   timerWheelRevolutions : \nat \\
   timerWheelRevolutionsLeft : \nat \\
   expirationCallbackAddr : MemoryAddressType \\
   wheelSpokeIndex : TimerWheelSpokeIndexType
\where
   timerWheelRevolutionsLeft \leq timerWheelRevolutions
\also
   timerState = timerRunning \implies expirationCallbackAddr \neq nullAddress
\end{schema}

\begin{schema}{ThreadType}
   id : ThreadIdType \\
   state : ThreadStateType \\
   currentPriority : ThreadPriorityType \\
   basePriority : ThreadPriorityType \\
   atomicLevel : AtomicLevelType \\
   builtinTimerId : TimerIdType \\
   builtinCondvarId : CondvarIdType \\
   waitingOnCondvarId : CondvarIdType \\
   waitingOnMutexId : MutexIdType \\
   ownedMutexes : \iseq ValidMutexIdType \\
   savedStackPointer : MemoryAddressType \\
   stack : AddressRangeType \\
   stackSavedCpuContext : CpuRegistersType \\
   privilegedNestingCounter : \nat \\
   timeSliceLeftUs : \nat
\where
   state \neq threadNotCreated \implies \\
   \t1 (id \neq invalidThreadId \land \\
   \t1 builtinTimerId \neq invalidTimerId \land \\
   \t1 builtinCondvarId \neq invalidCondvarId \land \\
   \t1 basePriority \neq invalidThreadPriority \land \\
   \t1 currentPriority \neq invalidThreadPriority \land \\
   \t1 savedStackPointer \in zAddressRange(stack))
\also
   currentPriority \geq basePriority
\also
   state = threadBlockedOnCondvar \iff \\
   \t1 waitingOnCondvarId \neq invalidCondvarId
\also
   state = threadBlockedOnMutex \iff \\
   \t1  waitingOnMutexId \neq invalidMutexId
\also
   waitingOnCondvarId \neq invalidCondvarId \implies \\
   \t1 waitingOnMutexId = invalidMutexId
\also
   waitingOnMutexId \neq invalidMutexId \implies \\
   \t1 waitingOnCondvarId = invalidCondvarId
\also
   waitingOnMutexId \notin \ran ownedMutexes
\end{schema}

\begin{schema}{CondvarType}
   id : CondvarIdType \\
   wakeupAtomicLevel : AtomicLevelType \\
   wakeupMutexId : MutexIdType \\
   waitingThreadsQueue : ThreadPriorityQueueType
\where
   wakeupAtomicLevel \neq atomicLevelNone \implies wakeupMutexId = invalidMutexId
\end{schema}

\begin{schema}{MutexType}
   id : MutexIdType \\
   ownerThreadId : ThreadIdType \\
   recursiveCount : \nat \\
   ceilingPriority : ThreadPriorityType \\
   waitingThreadsQueue : ThreadPriorityQueueType
\where
   waitingThreadsQueue.waitingThreadsCount \neq 0 \implies \\
   \t1 ownerThreadId \neq invalidThreadId
\also
   ceilingPriority \neq invalidThreadPriority \implies \\
   (\forall p: ValidThreadPriorityType | \\
   \t1     waitingThreadsQueue.threadQueues(p) \neq \emptyset @ \\
   \t1     p \leq ceilingPriority)
\end{schema}

\section{HiRTOS Boot-time Initialization}

When \verb`HiRTOS.Initialize` is called for each CPU core, the idle thread
and the tick timer thread for that CPU are created, but the thread
scheduler is not started yet:

\begin{schema}{HiRtosInitialize}
   HiRtos' \\
   HiRtosCpuInstanceInitialize \\
   cpuId? : CpuIdType \\
\where
   cpuId' = cpuId?
\also
   \theta HiRtosCpuInstanceType' = rtosCpuInstances'(cpuId?)
\also
   interruptNestingLevelStack'.zCpuId = cpuId?
\end{schema}

\begin{schema}{HiRtosCpuInstanceInitialize}
   HiRtosCpuInstanceElaboration
\where
    idleThreadId' \neq invalidThreadId
\also
    tickTimerThreadId' \neq invalidThreadId
\also
    tickTimerThreadId' \neq idleThreadId'
\also
    \dom threads' = \{~ idleThreadId', tickTimerThreadId' ~\}
\also
    \dom condvars' = \\
   \{~ (threads'(idleThreadId')).builtinCondvarId, \\
      (threads'(tickTimerThreadId')).builtinCondvarId ~\}
\also
    \dom timers' = \\
   \{~ (threads'(idleThreadId')).builtinTimerId, \\
       (threads'(tickTimerThreadId')).builtinTimerId ~\}
\also
    zCpuInterruptMaskingState' = cpuInterruptsEnabled
\also
    zCpuPrivilege' = cpuUnprivileged
\also
    zMemoryProtectionState' = memoryProtectionOn
\also
    runnableThreadsQueue'.threadQueues(min~ ValidThreadPriorityType) \\
    \t1 = \langle idleThreadId' \rangle
\also
    runnableThreadsQueue'.threadQueues(max~ ValidThreadPriorityType) \\
    \t1 = \langle tickTimerThreadId' \rangle
\also
   \forall p : ValidThreadPriorityType \setminus \\
   \t2   \{~ min~ ValidThreadPriorityType, max~ ValidThreadPriorityType ~\} @ \\
   \t1 runnableThreadsQueue'.threadQueues(p) = \emptyset
\end{schema}

\begin{schema}{HiRtosCpuInstanceElaboration}
    HiRtosCpuInstanceType' \\
    InterruptNestingLevelStackElaboration
\where
    threadSchedulerState' = threadSchedulerStopped
\also
    currentThreadId' = invalidThreadId
\also
    currentAtomicLevel' = atomicLevelNone
\also
    currentCpuExecutionMode' = cpuExecutingResetHandler
\also
    idleThreadId' = invalidThreadId
\also
    tickTimerThreadId' = invalidThreadId
\also
    threads' = \emptyset
\also
    condvars' = \emptyset
\also
    timers' = \emptyset
\also
    timerTicksSinceBoot' = 0
\end{schema}

\begin{schema}{InterruptNestingLevelStackElaboration}
   InterruptNestingLevelStackType' \\
   InterruptNestingLevelElaboration
\where
   currentInterruptNestingCounter' = 1 \\
\also
   \forall x: ActiveInterruptNestingCounterType @ \\
\t1   interruptNestingLevels'(x) = \theta InterruptNestingLevelType' \\
\end{schema}

\begin{schema}{InterruptNestingLevelElaboration}
   InterruptNestingLevelType'
\where
   interruptId' = invalidInterruptId
\also
   interruptNestingCounter' = 0
\also
   savedStackPointer' = nullAddress
\also
   atomicLevel' = atomicLevelNone
\end{schema}

\begin{schema}{TimerWheelElaboration}
   TimerWheelType'
\where
   \ran wheelSpokesHashTable' = \{~ \emptyset ~\}
\also
   currentWheelSpokeIndex' = \\
   \t1 min~ValidTimerWheelSpokeIndexType
\end{schema}

\section{HiRTOS Callable Services}

\subsection{\emph{HiRTOS} Threads Operations}

\subsubsection{Create a new thread}

A thread can be created by calling \verb`HiRTOS.Thread.Create_Thread`. Threads are allocated from the pool of
thread objects of the calling CPU:

\begin{schema}{CreateThread}
   \Delta HiRtosCpuInstanceType \\
   InitializeNewThread \\
   priority? : ValidThreadPriorityType
\where
   threadId! \notin \dom threads
\also
   condvarId! \notin \dom condvars
\also
   timerId! \notin \dom timers
\also
   threadId! \in \dom threads'
\also
   condvarId! \in \dom condvars'
\also
   timerId! \in \dom timers'
\also
   threads'(threadId!) = \theta ThreadType'
\also
    runnableThreadsQueue'.threadQueues(priority?) = \\
    \t1 runnableThreadsQueue.threadQueues(priority?) \cat \langle threadId! \rangle
\end{schema}

\begin{schema}{InitializeNewThread}
   ThreadType' \\
   condvarId! : ValidCondvarIdType \\
   timerId! : ValidTimerIdType \\
   threadId! : ValidThreadIdType
\where
   threadId! \neq invalidThreadId
\also
   id' = threadId!
\also
   builtinTimerId' = timerId!
\also
   builtinCondvarId' = condvarId!
\also
   state' = threadRunnable
\also
   atomicLevel' = atomicLevelNone
\end{schema}

\begin{schema}{ThreadPriorityQueueInitialize}
   ThreadPriorityQueueType'
\where
   \forall p: ValidThreadPriorityType @ \\
\t1     threadQueues'(p) = \emptyset
\end{schema}

\begin{schema}{DequeueHighestPriorityThread}
   \Delta ThreadPriorityQueueType \\
   highestPriorityThreadId! : ValidThreadIdType
\where
   (\LET highestPrio == \\
   \t1 max~ (\dom (threadQueues \nrres \emptyset)) @ \\
   \t1 highestPriorityThreadId! = head~ (threadQueues(highestPrio)) \land \\
   \t1 threadQueues'(highestPrio) = tail~ (threadQueues(highestPrio)))
\end{schema}

\subsection{\emph{HiRTOS} Mutex Operations}

\subsubsection{Create a new mutex}

A mutex can be created by calling \verb`HiRTOS.Mutex.Create`. Mutexes are allocated from the pool of
mutex objects of the calling CPU:

\begin{schema}{CreateMutex}
   \Delta HiRtosCpuInstanceType \\
   InitializeNewMutex \\
\where
   mutexId! \notin \dom mutexes
\also
   mutexId! \in \dom mutexes'
\also
   \theta MutexType' = mutexes'(mutexId!)
\end{schema}

\begin{schema}{InitializeNewMutex}
   MutexType' \\
   ceilingPriority? : ThreadPriorityType \\
   mutexId! : ValidMutexIdType
\where
   mutexId! \neq invalidMutexId
\also
   id' = mutexId!
\also
   ownerThreadId' = invalidThreadId
\also
   recursiveCount' = 0
\also
   ceilingPriority' = ceilingPriority?
\also
   \forall p: ValidThreadPriorityType @ \\
\t1      waitingThreadsQueue'.threadQueues(p) = \emptyset
\end{schema}

If $ceilingPriority?$ is $invalidThreadPriority$ that means that the mutex follows the priority
inheritance protocol. Otherwise, it follows the priority ceiling protocol. In the priority inheritance
protocol, if the thread trying to acquire a busy mutex has higher priority than the thread currently
owning the mutex, the owning thread gets its priority raised to the priority of the waiting thread.
In the priority ceiling protocol, when a thread acquires a mutex, if the mutex's ceiling priority is
higher than the thread's priority, the thread gets its priority raised to the ceiling priority.

The $CreatedMutexMutableOperation$ schema below is used in the specifications of all the mutable
operations that can be performed on mutexes that were previously created by a call to
\verb'HiRTOS.Mutex.Create':

\begin{schema}{CreatedMutexMutableOperation}
   \Delta HiRtos \\
   \Delta HiRtosCpuInstanceType \\
   \Delta MutexType \\
   cpuId? : CpuIdType \\
   mutexId? : ValidMutexIdType
\where
   \theta HiRtosCpuInstanceType = rtosCpuInstances(cpuId?)
\also
   \theta HiRtosCpuInstanceType' = rtosCpuInstances'(cpuId?)
\also
   \theta MutexType = mutexes(mutexId?)
\also
   \theta MutexType' = mutexes'(mutexId?)
\end{schema}

\subsubsection{Acquire a mutex}

A thread acquires a mutex by calling \verb`HiRTOS.Mutex.Acquire`, according to the contract
specified by the $AcquireMutex$ schema:

\begin{schema}{AcquireAvailableMutex}
   CreatedMutexMutableOperation
\where
   ownerThreadId = invalidThreadId \lor \\
   (ownerThreadId = currentThreadId \implies \\
    recursiveCount' = recursiveCount + 1)
\also
   ownerThreadId' = currentThreadId
\also
(ceilingPriority \neq invalidThreadPriority \land \\
 (threads(currentThreadId)).currentPriority < \\
 \t1    ceilingPriority) \implies \\
 (threads'(currentThreadId)).currentPriority = \\
 \t1    ceilingPriority
\also
(threads'(currentThreadId)).ownedMutexes = \\
\t1 (threads(currentThreadId)).ownedMutexes \cat \langle mutexId? \rangle
\end{schema}

\begin{schema}{WaitOnUnavailableMutex}
   CreatedMutexMutableOperation \\
   DequeueHighestPriorityThread
\where
   runnableThreadsQueue = \theta ThreadPriorityQueueType
\also
   runnableThreadsQueue' = \theta ThreadPriorityQueueType'
\also
   ownerThreadId \neq invalidThreadId
\also
   currentThreadId \neq ownerThreadId
\also
   currentThreadId' \neq currentThreadId
\also
(\LET oldCurrentPriority == \\
\t1 (threads(currentThreadId)).currentPriority @ \\
(ceilingPriority = invalidThreadPriority \land \\
 oldCurrentPriority > \\
 \t1 (threads(ownerThreadId)).currentPriority) \implies \\
 (threads'(ownerThreadId)).currentPriority = \\
 \t1 oldCurrentPriority \\
\land \\
 currentThreadId' \neq ownerThreadId \implies \\
 ((threads'(currentThreadId')).currentPriority \geq \\
 \t1 (threads'(ownerThreadId)).currentPriority \lor \\
 (threads'(ownerThreadId)).state \in  \{threadBlockedOnMutex , threadBlockedOnCondvar\}) \\
\land \\
 (threads'(currentThreadId)).state = threadBlockedOnMutex \\
\land \\
currentThreadId \in \\
\t1 \ran (waitingThreadsQueue'.threadQueues(oldCurrentPriority)))
\also
ceilingPriority \neq invalidThreadPriority \implies \\
((threads(currentThreadId)).currentPriority \leq \\
 \t1 (threads'(ownerThreadId)).currentPriority \land \\
 (threads'(ownerThreadId)).state \in \{threadBlockedOnMutex , threadBlockedOnCondvar\})
\also
   currentThreadId' \neq currentThreadId
\also
   currentThreadId' = highestPriorityThreadId!
\end{schema}

\begin{zed}
   AcquireMutex \defs \\
   \t1 AcquireAvailableMutex \lor WaitOnUnavailableMutex
\end{zed}

\subsubsection{Release a mutex}

A thread releases a mutex by calling \verb`HiRTOS.Mutex.Release`, according to the contract
specified by the $ReleaseMutex$ schema:

\begin{schema}{ReleaseMutex}
   CreatedMutexMutableOperation \\
   DequeueHighestPriorityThread
\where
   waitingThreadsQueue = \theta ThreadPriorityQueueType
\also
   waitingThreadsQueue' = \theta ThreadPriorityQueueType'
\also
   mutexId? = head~ (threads(currentThreadId)).ownedMutexes
\also
   (threads'(currentThreadId)).ownedMutexes = tail~ (threads(currentThreadId)).ownedMutexes
\also
   (\LET p == (threads(highestPriorityThreadId!)).currentPriority @ \\
   \t1 runnableThreadsQueue'.threadQueues(p) = \\
   \t2 runnableThreadsQueue.threadQueues(p) \cat \langle highestPriorityThreadId! \rangle)
\end{schema}

\subsection{\emph{HiRTOS} Condition Variable Operations}

\subsubsection{Create a new condition variable}

A condition variable can be created by calling \verb`HiRTOS.Condvar.Create`. Condvars are allocated
from the pool of condvar objects of the calling CPU:

\begin{schema}{CreateCondvar}
   \Delta HiRtosCpuInstanceType \\
   InitializeNewCondvar \\
\where
   condvarId! \notin \dom condvars
\also
   condvarId! \in \dom condvars'
\also
   condvars'(condvarId!) = \theta CondvarType'
\end{schema}

\begin{schema}{InitializeNewCondvar}
   CondvarType' \\
   ThreadPriorityQueueInitialize \\
   condvarId! : ValidCondvarIdType
\where
   waitingThreadsQueue' = \theta ThreadPriorityQueueType'
\also
   condvarId! \neq invalidCondvarId
\also
   id' = condvarId!
\also
   wakeupAtomicLevel' = atomicLevelNone
\also
   wakeupMutexId' = invalidMutexId
\end{schema}

The $CreatedCondvarMutableOperation$ schema below is used in the specifications of all the mutable
operations that can be performed on condition variables that were previously created by a call to
\verb'HiRTOS.Condvar.Create':

\begin{schema}{CreatedCondvarMutableOperation}
   \Delta HiRtos \\
   \Delta HiRtosCpuInstanceType \\
   \Delta CondvarType \\
   cpuId? : CpuIdType \\
   condvarId? : ValidCondvarIdType
\where
   rtosCpuInstances(cpuId?) = \theta HiRtosCpuInstanceType
\also
   rtosCpuInstances'(cpuId?) = \theta HiRtosCpuInstanceType'
\also
   condvars(condvarId?) = \theta CondvarType
\also
   condvars'(condvarId?) = \theta CondvarType'
\end{schema}

\subsubsection{Wait on a condition variable}

A thread waits on a condition variable by calling \verb`HiRTOS.Condvar.Wait`, according to the contract
specified by the $WaitOnCondvar$ schema:

\begin{schema}{WaitOnCondvar}
   CreatedCondvarMutableOperation \\
   DequeueHighestPriorityThread \\
   mutexId? : ValidMutexIdType
\where
   runnableThreadsQueue = \theta ThreadPriorityQueueType
\also
   runnableThreadsQueue' = \theta ThreadPriorityQueueType'
\also
   mutexId? \in \ran (threads(currentThreadId)).ownedMutexes
\also
   mutexId? \notin \ran (threads'(currentThreadId)).ownedMutexes
\also
   wakeupMutexId' = mutexId?
\also
   (\LET p == (threads(currentThreadId)).currentPriority @ \\
    \t1 waitingThreadsQueue'.threadQueues(p) = \\
    \t2 waitingThreadsQueue.threadQueues(p) \cat \langle currentThreadId \rangle)
\also
   currentThreadId' \neq currentThreadId
\also
   currentThreadId' = highestPriorityThreadId!
\end{schema}

\subsubsection{Signal a condition variable}

A thread signals a condition variable by calling \verb`HiRTOS.Condvar.Signal`, according to the contract
specified by the $SignalCondvar$ schema.
Signaling a condition variable wakes up the highest priority thread waiting on the
condition variable.

\begin{schema}{SignalCondvar}
   CreatedCondvarMutableOperation \\
   DequeueHighestPriorityThread
\where
   waitingThreadsQueue = \theta ThreadPriorityQueueType
\also
   waitingThreadsQueue' = \theta ThreadPriorityQueueType'
\also
   wakeupMutexId \in \ran (threads'(highestPriorityThreadId!)).ownedMutexes
\also
   (\LET p == (threads(highestPriorityThreadId!)).currentPriority @ \\
   \t1 runnableThreadsQueue'.threadQueues(p) = \\
   \t2 runnableThreadsQueue.threadQueues(p) \cat \langle highestPriorityThreadId! \rangle)
\end{schema}

\subsubsection{Broadcast on a condition variable}

A thread broadcasts on a condition variable by calling \verb`HiRTOS.Condvar.Broadcast`, according to the contract
specified by the $BroadcastCondvar$ schema.
Broadcasting on a condition variable wakes up all threads waiting on the condition variable.

\begin{schema}{BroadcastCondvar}
   CreatedCondvarMutableOperation \\
\where
   (\forall p: ValidThreadPriorityType | \\
   \t1     waitingThreadsQueue.threadQueues(p) \neq \emptyset @ \\
   \t1     waitingThreadsQueue'.threadQueues(p) = \emptyset \land \\
   \t1     runnableThreadsQueue'.threadQueues(p) = \\
   \t2     runnableThreadsQueue.threadQueues(p) \cat \\
   \t2     waitingThreadsQueue.threadQueues(p))
\end{schema}

\subsection{\emph{HiRTOS} Software Timer Operations}

\subsubsection{Create a new software timer}

A software timer can be created by calling \verb`HiRTOS.Timer.Create`. Timers are allocated
from the pool of timer objects of the calling CPU:

\begin{schema}{CreateTimer}
   \Delta HiRtosCpuInstanceType \\
   InitializeNewTimer
\where
   timerId! \notin \dom timers
\also
   timerId! \in \dom timers'
\also
   timers'(timerId!) = \theta TimerType'
\end{schema}

\begin{schema}{InitializeNewTimer}
   TimerType' \\
   timerId! : ValidTimerIdType
\where
   timerId! \neq invalidTimerId
\also
   id' = timerId!
\also
   timerKind' = oneShotTimer
\also
   timerState' = timerStopped
\also
   timerWheelRevolutions' = 0
\also
   timerWheelRevolutionsLeft' = 0
\also
   expirationCallbackAddr' = nullAddress
\also
   wheelSpokeIndex' = invalidTimerWheelSpokeIndex
\end{schema}

The $CreatedTimerMutableOperation$ schema below is used in the specifications of all the mutable
operations that can be performed on software timers that were previously created by a call to
\verb'HiRTOS.Timer.Create':

\begin{schema}{CreatedTimerMutableOperation}
   \Delta HiRtos \\
   \Delta HiRtosCpuInstanceType \\
   \Delta TimerType \\
   cpuId? : CpuIdType \\
   timerId? : ValidTimerIdType
\where
   rtosCpuInstances(cpuId?) = \theta HiRtosCpuInstanceType
\also
   rtosCpuInstances'(cpuId?) = \theta HiRtosCpuInstanceType'
\also
   timers(timerId?) = \theta TimerType
\also
   timers'(timerId?) = \theta TimerType'
\end{schema}

\subsubsection{Start a software timer}

A software timer is started by calling \verb`HiRTOS.Timer.Start_Timer`, according to the contract
specified by the $StartTimer$ schema:

\begin{schema}{StartTimer}
   CreatedTimerMutableOperation \\
   expirationTimeUs? : \nat \\
   expirationCallbackAddr? : MemoryAddressType \\
   timerKind? : TimerKindType
\where
   expirationCallbackAddr? \neq nullAddress
\also
   expirationCallbackAddr' = expirationCallbackAddr?
\also
   timerKind' = timerKind?
\also
   (\LET expirationTimeTicks == expirationTimeUs? \div TickTimerPeriodUs @ \\
      \t1 wheelSpokeIndex' = \\
      \t2 (timerWheel.currentWheelSpokeIndex + expirationTimeTicks) \mod numTimerWheelSpokes \land \\
      \t1 timerWheelRevolutions' = expirationTimeTicks \div numTimerWheelSpokes \land \\
      \t1 timerWheelRevolutionsLeft' = timerWheelRevolutions' \land \\
      \t1 timerWheel'.wheelSpokesHashTable(wheelSpokeIndex') = \\
      \t2    timerWheel.wheelSpokesHashTable(wheelSpokeIndex') \cup \{~ timerId? ~\})
\end{schema}

\subsubsection{Stop a software timer}

A software timer is stopped by calling \verb`HiRTOS.Timer.Stop_Timer`, according to the contract
specified by the $StopTimer$ schema:

\begin{schema}{StopTimer}
   CreatedTimerMutableOperation \\
\where
   expirationCallbackAddr' = nullAddress
\also
   timerWheel'.wheelSpokesHashTable(wheelSpokeIndex) = \\
   \t1  timerWheel.wheelSpokesHashTable(wheelSpokeIndex) \setminus \{~ timerId? ~\}
\end{schema}

\subsubsection{Pointer-less Linked list}

Thread queues, mutex lists and timer sets are refined as pointer-less linked lists.
Pointer-less linked lists use array indices instead of physical pointers. The $GenericLinkedLists$
schema represents a generic pointer-less linked list in which the links that chain the
list toegether are values of type $ElementIdType$ which corresponds to indices of some object array.

\begin{schema}{GenericLinkedList}[ElementIdType]
   head : ElementIdType \\
   tail : ElementIdType \\
   length : \nat \\
   nextElement : ElementIdType \finj ElementIdType \\
   prevElement : ElementIdType \finj ElementIdType
\where
   length \leq \# ElementIdType
\also
   length = \# (\dom nextElement)
\also
  \dom nextElement = \dom prevElement
\also
  \dom nextElement = \dom prevElement
\also
   length \leq 1 \iff head = tail
\also
   length \geq 2 \iff \\
\t1   (nextElement^{length - 1}(head) = tail \land prevElement^{length - 1}(tail) = head)
\also
   nextElement\plus \cap \id ElementIdType = \emptyset
\also
   prevElement\plus \cap \id ElementIdType = \emptyset
\also
    \forall x: \dom nextElement @ \\
\t1    (x \neq tail \implies prevElement(nextElement(x)) = x) \land \\
\t1    (x \neq head \implies nextElement(prevElement(x)) = x)
\end{schema}

$ThreadQueueType$ which is an injective sequence is refined as the $RefinedThreadQueueType$ schema:

\begin{schema}{RefinedThreadQueueType}
   GenericLinkedList[ThreadIdType] \\
\where
   nextElement(tail) = invalidThreadId
\also
   prevElement(tail) = invalidThreadId
\also
  length = 0 \iff head = invalidThreadId
\also
  tail = invalidThreadId \iff head = invalidThreadId
\end{schema}

$MutexListType$ which is also an injective sequencce is refined as the $RefinedMutexListType$ schema:

\begin{schema}{RefinedMutexListType}
   GenericLinkedList[MutexIdType] \\
\where
   nextElement(tail) = invalidMutexId
\also
   prevElement(tail) = invalidMutexId
\also
  length = 0 \iff head = invalidMutexId
\also
  tail = invalidMutexId \iff head = invalidMutexId
\end{schema}

The set of timers associated with each timerwheel spoke is refined as the
$TimerListType$ schema:

\begin{schema}{TimerListType}
   GenericLinkedList[TimerIdType] \\
\where
   nextElement(tail) = invalidTimerId
\also
   prevElement(tail) = invalidTimerId
\also
  length = 0 \iff head = invalidTimerId
\also
  tail = invalidTimerId \iff head = invalidTimerId
\end{schema}

\section{HiRTOS Thread Context Switching}

\subsection{Asynchronous Thread Context Switch}

In HiRTOS, thread preemption is implemented by invoking the thread scheduler
on the exit path of an interrupt handler. When an interrupt fires while
a thread is running, the executing thread's CPU context is saved
on thread's stack by the interrupt handler prolog. Then, before calling the
actual interrupt handler, the stack is switched to the interrupt handling stack.
After the interrupt handler returns, the interrupt handler epilog invokes
the HiRTOS thread scheduler, to select the highest priority runnable thread.
Then, if the newly selected thread is different from  the one that was running before
the interrupt, the extended context of the old thread is saved and the extended
context of the new thread is restored.

\begin{figure}[H]
   \centering
   \scalebox{0.40} {
      \input{uml_diagrams/hirtos_scheduler_invocation_from_interrupt_part1.latex}
   }
   \caption{HiRTOS Asynchronous Thread Context Switch - part 1}
   \label{HiRTOSumlSeqDiagram1}
\end{figure}

\begin{figure}[H]
   \centering
   \scalebox{0.35} {
      \input{uml_diagrams/hirtos_scheduler_invocation_from_interrupt_part2.latex}
   }
   \caption{HiRTOS Asynchronous Thread Context Switch - part 2}
   \label{HiRTOSumlSeqDiagram2}
\end{figure}

\subsection{Synchronous Thread Context Switch}

In HiRTOS, a synchronous thread context switch occurs in the following cases:
\begin{itemize}
\item When a thread calls \verb`HiRTOS.Condvar.Wait`
\item When a thread calls \verb`HiRTOS.Condvar.Signal` or \verb`HiRTOS.Condvar.Broadcast`,
      and there are threads waiting on the condition variable
\item When a thread calls \verb`HiRTOS.Mutex.Acquire` and the mutex is not available
\item When a thread calls \verb`HiRTOs.Mutex.Release` and there are threads waiting
      to acquire the mutex
\item When a thread calls \verb`HiRTOS.Thread.Thread_Delay_Until` (calls \verb`HiRTOS.Condvar.Wait`)
\item When a thread calls \verb`HiRTOS.Thread.Suspend_Current_Thread`
\item When a thread calls \verb`HiRTOS.Thread.Resume_Thread`
\item When a thread calls \verb`HiRTOS.Restore_Atomic_Level` and the old atomic level is
      \verb`Atomic_Level_None`
\end{itemize}

\begin{figure}[H]
   \centering
   \scalebox{0.40} {
      \input{uml_diagrams/hirtos_scheduler_invocation_from_thread_part1.latex}
   }
   \caption{HiRTOS Synchronous Thread Context Switch - part 1}
   \label{HiRTOSumlSeqDiagram3}
\end{figure}

\begin{figure}[H]
   \centering
   \scalebox{0.40} {
      \input{uml_diagrams/hirtos_scheduler_invocation_from_thread_part2.latex}
   }
   \caption{HiRTOS Synchronous Thread Context Switch - part 2}
   \label{HiRTOSumlSeqDiagram4}
\end{figure}

A special case is the initial thread context switch, which occurs when the
HiRTOS thread scheduler is started, when the application calls
\verb`HiRTOS.Start_Thread_Scheduler`.

\begin{figure}[H]
   \centering
   \scalebox{0.40} {
      \input{uml_diagrams/hirtos_scheduler_initial_invocation_part1.latex}
   }
   \caption{HiRTOS Initial Thread Context Switch - part 1}
   \label{HiRTOSumlSeqDiagram5}
\end{figure}

\begin{figure}[H]
   \centering
   \scalebox{0.40} {
      \input{uml_diagrams/hirtos_scheduler_initial_invocation_part2.latex}
   }
   \caption{HiRTOS Initial Thread Context Switch - part 2}
   \label{HiRTOSumlSeqDiagram6}
\end{figure}

\subsection{TLA+/PlusCal Model of the HiRTOS Thread Scheduler}

The HiRTOS thread scheduler has been modeled in TLA+/PlusCal \cite{tla1, tla2}.
The HiRTOS TLA+/PlusCal model can be found \href{run:./tla_models/HiRTOS.pdf}{here}.
The following safety invariants were verified with the TLC model checker \cite{tlc}:

\begin{itemize}
\item There can be at most only one "running" thread

\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
   IF HiRTOS.Current_Thread_Id /= "Invalid_Thread_Id" THEN
      /\ Cardinality({ t \in Threads : Thread_Objects[t].State = "Running" }) = 1
      /\ HiRTOS.Current_Thread_Id =
         CHOOSE t \in Threads : Thread_Objects[t].State = "Running"
   ELSE
      { t \in Threads : Thread_Objects[t].State = "Running" } = {}
\end{lstlisting}

\item The running thread is not in any queue
\begin{lstlisting}
(HiRTOS.Interrupts_Enabled /\
 HiRTOS.Current_Thread_Id /= "Invalid_Thread_Id") =>
   (/\ Thread_Objects[HiRTOS.Current_Thread_Id].State = "Running"
    /\ Thread_Objects[HiRTOS.Current_Thread_Id].Waiting_On_Condvar_Id =
          "Invalid_Condvar_Id"
    /\ Thread_Objects[HiRTOS.Current_Thread_Id].Waiting_On_Mutex_Id =
          "Invalid_Mutex_Id"
    /\ ~Is_Thread_In_Priority_Queue(HiRTOS.Runnable_Threads_Queue,
                                    HiRTOS.Current_Thread_Id)
    /\ \A m \in Mutexes :
         ~Is_Thread_In_Priority_Queue(Mutex_Objects[m].Waiting_Threads_Queue,
                                      HiRTOS.Current_Thread_Id)
    /\ \A cv \in Condvars :
         ~Is_Thread_In_Priority_Queue(Condvar_Objects[cv].Waiting_Threads_Queue,
                                      HiRTOS.Current_Thread_Id)
   )
\end{lstlisting}

\item All Runnable threads are in the Runnable threads queue and no other queue
\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
\A t \in Threads : Thread_Objects[t].State = "Runnable" =>
   /\ Thread_Objects[t].Waiting_On_Condvar_Id = "Invalid_Condvar_Id"
   /\ Thread_Objects[t].Waiting_On_Mutex_Id = "Invalid_Mutex_Id"
   /\ Is_Thread_In_Priority_Queue(HiRTOS.Runnable_Threads_Queue, t)
   /\ Is_Thread_In_Priority_Queue_In_Only_One_Queue(
         HiRTOS.Runnable_Threads_Queue, t)
   /\ \A m \in Mutexes :
         ~Is_Thread_In_Priority_Queue(Mutex_Objects[m].Waiting_Threads_Queue, t)
   /\ \A cv \in Condvars :
         ~Is_Thread_In_Priority_Queue(
            Condvar_Objects[cv].Waiting_Threads_Queue, t)
\end{lstlisting}

\item Each thread blocked on a mutex in only one mutex's wait queue and no other queue
\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
\A t \in Threads :
LET
   thread_obj == Thread_Objects[t]
IN
   thread_obj.State = "Blocked_On_Mutex" =>
   /\ thread_obj.Waiting_On_Mutex_Id /= "Invalid_Mutex_Id"
   /\ thread_obj.Waiting_On_Condvar_Id = "Invalid_Condvar_Id"
   /\ (LET
         mutex_obj == Mutex_Objects[thread_obj.Waiting_On_Mutex_Id]
       IN
         /\ Is_Thread_In_Priority_Queue(mutex_obj.Waiting_Threads_Queue, t)
         /\ Is_Thread_In_Priority_Queue_In_Only_One_Queue(
               mutex_obj.Waiting_Threads_Queue, t))
   /\ ~Is_Thread_In_Priority_Queue(HiRTOS.Runnable_Threads_Queue, t)
   /\ \A m \in Mutexes \ { thread_obj.Waiting_On_Mutex_Id } :
         ~Is_Thread_In_Priority_Queue(
            Mutex_Objects[m].Waiting_Threads_Queue, t)
   /\ \A cv \in Condvars :
         ~Is_Thread_In_Priority_Queue(
            Condvar_Objects[cv].Waiting_Threads_Queue, t)
\end{lstlisting}

\item Each thread blocked on a condvar is in only one condvar\'s wait queue and no other queue
\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
\A t \in Threads :
LET
   thread_obj == Thread_Objects[t]
IN
   thread_obj.State = "Blocked_On_Condvar" =>
   /\ thread_obj.Waiting_On_Condvar_Id /= "Invalid_Condvar_Id"
   /\ thread_obj.Waiting_On_Mutex_Id = "Invalid_Mutex_Id"
   /\ (LET
        condvar_obj == Condvar_Objects[thread_obj.Waiting_On_Condvar_Id]
       IN
         /\ Is_Thread_In_Priority_Queue(
               condvar_obj.Waiting_Threads_Queue, t)
         /\ Is_Thread_In_Priority_Queue_In_Only_One_Queue(
               condvar_obj.Waiting_Threads_Queue, t))
   /\ ~Is_Thread_In_Priority_Queue(HiRTOS.Runnable_Threads_Queue, t)
   /\ \A cv \in Condvars \ { thread_obj.Waiting_On_Condvar_Id } :
         ~Is_Thread_In_Priority_Queue(
            Condvar_Objects[cv].Waiting_Threads_Queue, t)
   /\ \A m \in Mutexes :
         ~Is_Thread_In_Priority_Queue(
            Mutex_Objects[m].Waiting_Threads_Queue, t)
\end{lstlisting}

\item Each mutex that is currently owned by a thread must be in the list of mutexes owned by that thread
\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
\A m \in Mutexes :
LET
   t == Mutex_Objects[m].Owner_Thread_Id
IN
   t /= "Invalid_Thread_Id" =>
      m \in Range(Thread_Objects[t].Owned_Mutexes)
\end{lstlisting}

\item If a mutex is not owned by a thread, its wait queue should be empty
\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
\A m \in Mutexes :
   Mutex_Objects[m].Owner_Thread_Id = "Invalid_Thread_Id" =>
      Is_Thread_Priority_Queue_Empty(Mutex_Objects[m].Waiting_Threads_Queue)
\end{lstlisting}

\item The thread owning a mutex can never have lower priority than any thread waiting
for the mutex
\begin{lstlisting}
(HiRTOS.Interrupts_Enabled /\
 HiRTOS.Current_Thread_Id /= "Invalid_Thread_Id") =>
\A m \in Mutexes :
LET
   t == Mutex_Objects[m].Owner_Thread_Id
   prio_queue == Mutex_Objects[m].Waiting_Threads_Queue
IN
   (t /= "Invalid_Thread_Id" /\
    ~Is_Thread_Priority_Queue_Empty(prio_queue)) =>
   \A wt \in UNION { Range(q) : q \in Range(prio_queue) } :
      Thread_Objects[wt].State = "Blocked_On_Mutex" /\
      Thread_Objects[t].Current_Priority >= Thread_Objects[wt].Current_Priority
\end{lstlisting}

\item A thread not owning any mutex and not waiting on a condvar always has its current
priority set to its base priority
\begin{lstlisting}
HiRTOS.Interrupts_Enabled =>
\A t \in Threads :
   (Thread_Objects[t].Owned_Mutexes = <<>> /\
    Thread_Objects[t].State /= "Blocked_On_Condvar") =>
   Thread_Objects[t].Current_Priority = Thread_Objects[t].Base_Priority
\end{lstlisting}
\end{itemize}

Also, the following liveness properties were verified with TLC:

\begin{itemize}
\item Interrupts are not disabled indefinitely
\begin{lstlisting}
~HiRTOS.Interrupts_Enabled => <>HiRTOS.Interrupts_Enabled
\end{lstlisting}

\item Every thread waiting to acquire a mutex, eventually gets it:
\begin{lstlisting}
\A t \in Threads :
   Thread_Objects[t].State = "Waiting_On_Mutex" =>
   <>(Thread_Objects[t].State = "Runnable")
\end{lstlisting}

\item Every thread waiting on a condvar is eventually awaken:
\begin{lstlisting}
\A t \in Threads :
   Thread_Objects[t].State = "Waiting_On_Mutex" =>
   <>(Thread_Objects[t].State = "Runnable")
\end{lstlisting}
\end{itemize}

\clearpage
\chapter{HiRTOS Separation Kernel Z Specification}

\section{Separation Kernel Data Structures}

\subsection{Separation Kernel Configuration Parameters}

Constants defined here represent compile-time configuration parameters for the
\emph{HiRTOS} Separation kernel.

\begin{axdef}
    maxNumPartitionsPerCpu: \nat_1 \\
    TickTimerPeriodUs: \nat_1 \\
    PartitionTimeSliceTicks: \nat_1
\end{axdef}

\subsection{Separation Kernel Primitive Types}

Below are the primitive types used in HiRTOS:

\begin{zed}
[PartitionIdType] \\
\# PartitionIdType = maxNumPartitionsPerCpu + 1 \\
\end{zed}

\begin{axdef}
   invalidPartitionId : PartitionIdType \\
\end{axdef}

\begin{zed}
    ValidPartitionIdType == \\
    \t1 PartitionIdType \setminus \{ invalidPartitionId \} \\
    PartitionQueueType == \iseq ValidPartitionIdType \\
    PartitionStateType ::= partitionNotCreated | \\
    \t5 partitionRunnable | partitionRunning | \\
    \t5 partitionSuspended \\
    PartitionSchedulerStateType ::= \\
    \t1 partitionSchedulerStopped | partitionSchedulerRunning \\
    AddressRangeType == MemoryAddressType \cross MemoryAddressType \\
\end{zed}

\subsection{Separation Kernel State Variables}

The $HiRtosSeparationKernel$ schema represents the internal data
structures of the HiRTOS separation kernel.

\begin{schema}{HiRtosSeparationKernel}
    separationKernelCpuInstances: \\
    \t1 ValidCpuIdType \finj SeparationKernelCpuInstanceType \\
    zAllCreatedPartitionInstances: \finset PartitionType \\
\where
    \# separationKernelCpuInstances \geq 1
\also
    \forall i : \dom separationKernelCpuInstances @ \\
\t1   (separationKernelCpuInstances(i)).cpuId = i
\also
    zAllCreatedPartitionInstances = \\
\t1    \bigcup~\{~ i: ValidCpuIdType @ \\
\t2    \ran~ (separationKernelCpuInstances(i)).partitions ~\}
\also
    \bigcap~\{~ i: ValidCpuIdType @ \\
\t1    \ran~ (separationKernelCpuInstances(i)).partitions ~\} = \emptyset
\also
    \bigcap~\{~ r: \bigcup~\{~ p: zAllCreatedPartitionInstances @ p.savedHypervisorLevelMpuRegions~\} @ \\
    \t1 zAddressRange(r) ~\} = \emptyset
\end{schema}

\subsubsection{Per-CPU Separation Kernel Instance}

The state variables and internal data structures of each per-CPU \emph{HiRTOS} separation kernel instance
are described below:

\begin{schema}{SeparationKernelCpuInstanceType}
    cpuId: ValidCpuIdType \\
    interruptStack : AddressRangeType \\
    partitionSchedulerState: PartitionSchedulerStateType \\
    currentPartitionId: PartitionIdType \\
    timerTicksSinceBoot: \nat \\
    runnablePartitionsQueue : PartitionQueueType \\
    partitions: ValidPartitionIdType \finj PartitionType \\
    zCurrentCpuContext: CpuRegistersType \\
    zCurrentHypervisorLevelMpuRegions : \finset_1 AddressRangeType \\
    zCurrentSupervisorLevelMpuRegions : \finset AddressRangeType \\
    zCurrentSupervisorLevelInterruptVectorTableAddr : MemoryAddressType \\
    zCurrentSupervisorLevelInterruptsEnabled : \finset ValidInterruptIdType \\
    zCurrentHighestInterruptPriorityDisabled : InterruptPriorityType \\
\where
   zAddressRange(interruptStack) \neq \emptyset
\also
   currentPartitionId \neq invalidPartitionId \implies \\
   \t1 currentPartitionId \in \dom partitions \land \\
   \t1 zCurrentHypervisorLevelMpuRegions = \\
   \t2 (partitions(currentPartitionId)).savedHypervisorLevelMpuRegions \land \\
   \t1 zCurrentSupervisorLevelInterruptVectorTableAddr = \\
   \t2 (partitions(currentPartitionId)).savedInterruptVectorTableAddr \\
\also
   \forall p : \ran partitions @ \\
   \t1 \bigcap~\{~ i: p.savedHypervisorLevelMpuRegions @ zAddressRange(i) ~\} = \emptyset
\also
   \forall i : zCurrentSupervisorLevelMpuRegions @ \\
   \t1 \exists_1 j : zCurrentHypervisorLevelMpuRegions @ \\
   \t2 zAddressRange(i) \subseteq zAddressRange(j)
\end{schema}

\begin{schema}{PartitionType}
   id : PartitionIdType \\
   failoverPartitionId : PartitionIdType \\
   state : PartitionStateType \\
   timeSliceLeftUs : \nat \\
   savedCpuContext : CpuRegistersType \\
   savedHypervisorLevelMpuRegions : \finset_1 AddressRangeType \\
   savedSupervisorLevelMpuRegions : \finset AddressRangeType \\
   savedInterruptVectorTableAddr : MemoryAddressType \\
   savedInterruptsEnabled : \finset InterruptIdType \\
   savedHighestInterruptPriorityDisabled : InterruptPriorityType \\
\where
   state \neq partitionNotCreated \implies \\
   \t1 id \neq invalidPartitionId
\also
   failoverPartitionId \neq invalidPartitionId \implies \\
   \t1 failoverPartitionId \neq id
\also
   \bigcap~\{~ i: savedHypervisorLevelMpuRegions @ zAddressRange(i) ~\} = \emptyset
\also
   \emptyset \notin \{~ i: savedHypervisorLevelMpuRegions @ zAddressRange(i) ~\}
\also
   \forall i : savedSupervisorLevelMpuRegions @ \\
    \t1 \exists_1 j : savedHypervisorLevelMpuRegions @ \\
    \t2 zAddressRange(i) \subseteq zAddressRange(j)
\end{schema}

\subsection{Separation Kernel Boot-time Initialization}

At boot time, the HiRTOS separation kernel is initialized when the \\
\verb`HiRTOS.Separation_Kernel.Initialize` \emph{HiRTOS} API is
called on every CPU core:

\begin{schema}{HiRtosSeparationKernelInitialize}
    HiRtosSeparationKernel' \\
    SeparationKernelCpuInstanceInitialize \\
    cpuId? : CpuIdType
\where
   cpuId' = cpuId?
\also
    \theta SeparationKernelCpuInstanceType' = separationKernelCpuInstances'(cpuId?)
\end{schema}

\begin{schema}{SeparationKernelCpuInstanceInitialize}
   SeparationKernelCpuInstanceElaboration
%\where
\end{schema}

\begin{schema}{SeparationKernelCpuInstanceElaboration}
   SeparationKernelCpuInstanceType'
\where
   zAddressRange(interruptStack') \neq \emptyset
\also
    partitionSchedulerState' = partitionSchedulerStopped
\also
   currentPartitionId' = invalidPartitionId
\also
   timerTicksSinceBoot' = 0
\also
   runnablePartitionsQueue' = \langle \rangle
\also
   partitions' = \emptyset
\end{schema}

\section{Separation Kernel Callable Services}

\subsection{Partition Operations}

\subsubsection{Create a new partition}

A partition can be created by calling \verb`HiRTOS.Separation_Kernel.Partition.Create_Partition`.
Partitions are allocated from the pool of partition objects of the calling CPU:

\begin{schema}{CreatePartition}
   \Delta SeparationKernelCpuInstanceType \\
   InitializeNewPartition \\
\where
   partitionId! \notin \dom partitions
\also
   partitionId! \in \dom partitions'
\also
   partitions'(partitionId!) = partitions'(partitionId!)
\also
   runnablePartitionsQueue' = runnablePartitionsQueue \cat \langle partitionId! \rangle
\end{schema}

\begin{schema}{InitializeNewPartition}
   PartitionType' \\
   partitionId! : ValidPartitionIdType
\where
   id' = partitionId!
\also
   failoverPartitionId' = invalidPartitionId
\also
   state' = partitionRunnable
\also
   savedHypervisorLevelMpuRegions' \neq \emptyset
\also
   savedSupervisorLevelMpuRegions' = \emptyset
\also
   savedInterruptsEnabled' = \emptyset
\end{schema}

\begin{thebibliography}{9}

\bibitem{Zref}
Mike Spivey, ``Z Reference Card'', 1992 \\
\url{https://github.com/Spivoxity/fuzz/blob/master/doc/refcard3-pub.pdf}

\bibitem{Zrm}
Mike Spivey, ``The Z Reference Manual'', second edition, Prentice-Hall, 1992 \\
\url{http://spivey.oriel.ox.ac.uk/~mike/zrm/zrm.pdf}

\bibitem{WayofZ}
Jonathan Jacky, ``The Way of Z'', Cambridge Press, 1997 \\
\url{http://staff.washington.edu/jon/z-book/index.html}

\bibitem{Fuzz}
Mike Spivey, ``The Fuzz checker'' \\
\url{https://github.com/Spivoxity/fuzz}

\bibitem{SparkAda}
John W. McCormick, Peter C. Chapin,``Building High Integrity Applications with SPARK'', Cambridge University Press, 2015 \\
\url{https://www.amazon.com/Building-High-Integrity-Applications-SPARK/dp/1107040736}

\bibitem{gnatprove}
AdaCore,``Formal Verification with GNATprove'' \\
\url{https://docs.adacore.com/spark2014-docs/html/ug/en/gnatprove.html}

\bibitem{threads1}
Andrew D. Birrel, ``An Introduction to Programming with Threads'',
Digital Equipment Corporation, Systems Research Center, 1989 \\
\url{http://birrell.org/andrew/papers/035-Threads.pdf}

\bibitem{threads2}
Andrew D. Birrel et al, ``Synchronization Primitives for a Multiprocessor: A Formal Specification'',
Digital Equipment Corporation, Systems Research Center, 1987 \\
\url{https://dl.acm.org/doi/pdf/10.1145/37499.37509}

\bibitem{libcThreads}
ISO, ``N2731: Working draft of the C23 standard, section 7.26'', October 2021 \\
\url{http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2596.pdf#page=345&zoom=100,102,113}

\bibitem{prioCeiling}
Lui Sha et al, ``Priority Inheritance Protocols: An Approach to Real-Time Synchronization'', IEEE Transactions on Computers, September 1990 \\
\url{https://www.csie.ntu.edu.tw/~r95093/papers/Priority%20Inheritance%20Protocols%20An%20Approach%20to%20Real-Time%20Synchronization.pdf}

\bibitem{SepK1}
John Rushby, ``Design and Verification of Secure Systems'', ACM SIGOPS Operating Systems Review, 1981 \\
\url{https://www.csl.sri.com/users/rushby/papers/sosp81.pdf}

\bibitem{SepK2}
John Rushby, ``Partitioning in Avionics Architectures: Requirements, Mechanisms, and Assurance'', Technical Report. 1999 \\
\url{https://www.tc.faa.gov/its/worldpac/techrpt/ar99-58.pdf}

\bibitem{freeRTOS}
FreeRTOS \\
\url{https://www.freertos.org/}

\bibitem{cmsisRTOS}
CMSIS-RTOS API v2 (CMSIS-RTOS2) \\
\url{https://www.keil.com/pack/doc/CMSIS/RTOS2/html/group__CMSIS__RTOS.html}

\bibitem{tla1}
Leslie Lamport, ``Specifying Systems: The TLA+ Language and Tools for Hardware and Software Engineers'', Addison Wesley, 2003
\url{https://lamport.azurewebsites.net/tla/book.html?back-link=learning.html#book}

\bibitem{tla2}
`Hillel Wayne, `'`Practical TLA+: Planning Driven Development'', APress, 2018
\url{https://link.springer.com/book/10.1007/978-1-4842-3829-5}

\bibitem{tlc}
Leslie Lamport, ``The TLA+ Toolbox''
https://lamport.azurewebsites.net/tla/toolbox.html

\end{thebibliography}

\end{document}
